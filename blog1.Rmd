---
title: "Blog"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Bootstrapping StepAIC()

I work in the field of finance and find that people often rely on OLS regressions for doing predictive analysis. Itâ€™s easy to implement and everyone knows about it. OLS regression gives us a very well developed mathematical framework which can be used to develop linear relationships. These relationships can then be used to create forward looking projections. But what about the features? How does one go about selecting the right feature set which can be used to reliably predict the variable under consideration?

Stepwise variable selection is one of the most commonly used variable selection algorithms. The reliability of stepwise and or subset selection techniques is debatable. If you are a statistician chances are you are not a big fan of such algorithms. None the less, such techniques are popular and I have come across a lot of people using them.

One of the ways one could make the stepwise selection process more reliable is by bootstrapping it. The process can be broken down into the following steps:

